{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8773d13",
   "metadata": {},
   "source": [
    "# 1 — Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Dataset:** AMELIA (*Argument Mining Evaluation on Legal documents in ItAlian*)  \n",
    "**Task:** Classificazione binaria — *premise* (`prem`) vs *conclusion* (`conc`)  \n",
    "**Obiettivo:** Comprendere distribuzione, proprietà lessicali e caratteristiche delle classi prima di addestrare i modelli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f547a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=1.1)\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "DATASET_ID = \"nlp-unibo/AMELIA\"\n",
    "print(\"Loading AMELIA dataset...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfae1fb",
   "metadata": {},
   "source": [
    "## 1.1 — Caricamento e panoramica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba58c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(DATASET_ID)\n",
    "\n",
    "# Converti in DataFrame per ciascun split\n",
    "dfs = {}\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    df = ds[split].to_pandas()\n",
    "    df[\"split\"] = split\n",
    "    df[\"text_len_chars\"] = df[\"Text\"].str.len()\n",
    "    df[\"text_len_words\"] = df[\"Text\"].str.split().str.len()\n",
    "    dfs[split] = df\n",
    "\n",
    "df_all = pd.concat(dfs.values(), ignore_index=True)\n",
    "\n",
    "print(f\"Totale campioni: {len(df_all)}\")\n",
    "print(f\"Colonne: {list(df_all.columns)}\")\n",
    "print(\"\\nCampioni per split:\")\n",
    "print(df_all.groupby(\"split\").size().to_frame(\"count\"))\n",
    "print(\"\\nPrime 3 righe:\")\n",
    "df_all[[\"Text\", \"Component\", \"split\"]].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25336de1",
   "metadata": {},
   "source": [
    "## 1.2 — Distribuzione delle classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d17439",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "for ax, split in zip(axes, [\"train\", \"validation\", \"test\"]):\n",
    "    counts = dfs[split][\"Component\"].value_counts()\n",
    "    pct = counts / counts.sum() * 100\n",
    "    bars = ax.bar(counts.index, counts.values, color=[\"#4C72B0\", \"#DD8452\"])\n",
    "    ax.set_title(f\"{split.capitalize()} (n={counts.sum()})\")\n",
    "    ax.set_ylabel(\"Campioni\")\n",
    "    for bar, p in zip(bars, pct):\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height() + 8,\n",
    "            f\"{p:.1f}%\",\n",
    "            ha=\"center\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "fig.suptitle(\"Distribuzione classi per split\", fontsize=14, y=1.02)\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"../results/plots/class_distribution.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRapporto prem/conc:\")\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    counts = dfs[split][\"Component\"].value_counts()\n",
    "    ratio = counts.get(\"prem\", 0) / counts.get(\"conc\", 1)\n",
    "    print(\n",
    "        f\"  {split:12s}: {ratio:.1f}:1  ({counts.get('prem', 0)} prem, {counts.get('conc', 0)} conc)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32e7071",
   "metadata": {},
   "source": [
    "## 1.3 — Distribuzione della lunghezza dei testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e6564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Lunghezza in parole\n",
    "for label, color in [(\"prem\", \"#4C72B0\"), (\"conc\", \"#DD8452\")]:\n",
    "    subset = df_all[df_all[\"Component\"] == label]\n",
    "    axes[0].hist(\n",
    "        subset[\"text_len_words\"],\n",
    "        bins=50,\n",
    "        alpha=0.6,\n",
    "        label=f\"{label} (μ={subset['text_len_words'].mean():.0f})\",\n",
    "        color=color,\n",
    "        edgecolor=\"white\",\n",
    "    )\n",
    "axes[0].set_xlabel(\"Numero di parole\")\n",
    "axes[0].set_ylabel(\"Frequenza\")\n",
    "axes[0].set_title(\"Distribuzione lunghezza (parole)\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Lunghezza in caratteri\n",
    "for label, color in [(\"prem\", \"#4C72B0\"), (\"conc\", \"#DD8452\")]:\n",
    "    subset = df_all[df_all[\"Component\"] == label]\n",
    "    axes[1].hist(\n",
    "        subset[\"text_len_chars\"],\n",
    "        bins=50,\n",
    "        alpha=0.6,\n",
    "        label=f\"{label} (μ={subset['text_len_chars'].mean():.0f})\",\n",
    "        color=color,\n",
    "        edgecolor=\"white\",\n",
    "    )\n",
    "axes[1].set_xlabel(\"Numero di caratteri\")\n",
    "axes[1].set_ylabel(\"Frequenza\")\n",
    "axes[1].set_title(\"Distribuzione lunghezza (caratteri)\")\n",
    "axes[1].legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"../results/plots/text_length_distribution.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStatistiche lunghezza (parole):\")\n",
    "print(df_all.groupby(\"Component\")[\"text_len_words\"].describe().round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611a4203",
   "metadata": {},
   "source": [
    "## 1.4 — Analisi della tokenizzazione WordPiece (BERTino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b8b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"indigo-ai/BERTino\")\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "# Tokenizza tutti i testi\n",
    "all_texts = df_all[\"Text\"].tolist()\n",
    "encodings = tokenizer(all_texts, truncation=False, padding=False)\n",
    "token_lengths = [len(ids) for ids in encodings[\"input_ids\"]]\n",
    "df_all[\"token_length\"] = token_lengths\n",
    "\n",
    "# Statistiche troncamento\n",
    "n_truncated = sum(1 for tl in token_lengths if tl > MAX_LENGTH)\n",
    "pct_truncated = n_truncated / len(token_lengths) * 100\n",
    "\n",
    "print(f\"Lunghezza massima in token: {max(token_lengths)}\")\n",
    "print(f\"Lunghezza media: {np.mean(token_lengths):.1f} ± {np.std(token_lengths):.1f}\")\n",
    "print(f\"Mediana: {np.median(token_lengths):.0f}\")\n",
    "print(\n",
    "    f\"\\nSequenze troncate a max_length={MAX_LENGTH}: {n_truncated}/{len(token_lengths)} ({pct_truncated:.1f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd85c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribuzione token per classe\n",
    "for label, color in [(\"prem\", \"#4C72B0\"), (\"conc\", \"#DD8452\")]:\n",
    "    subset = df_all[df_all[\"Component\"] == label]\n",
    "    axes[0].hist(\n",
    "        subset[\"token_length\"],\n",
    "        bins=50,\n",
    "        alpha=0.6,\n",
    "        label=f\"{label} (μ={subset['token_length'].mean():.0f})\",\n",
    "        color=color,\n",
    "        edgecolor=\"white\",\n",
    "    )\n",
    "axes[0].axvline(\n",
    "    x=MAX_LENGTH, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"max_length={MAX_LENGTH}\"\n",
    ")\n",
    "axes[0].set_xlabel(\"Numero di token WordPiece\")\n",
    "axes[0].set_ylabel(\"Frequenza\")\n",
    "axes[0].set_title(\"Distribuzione lunghezza tokenizzata\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Box plot per classe\n",
    "sns.boxplot(\n",
    "    data=df_all, x=\"Component\", y=\"token_length\", ax=axes[1], palette=[\"#4C72B0\", \"#DD8452\"]\n",
    ")\n",
    "axes[1].axhline(\n",
    "    y=MAX_LENGTH, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"max_length={MAX_LENGTH}\"\n",
    ")\n",
    "axes[1].set_title(\"Token length per classe\")\n",
    "axes[1].set_ylabel(\"Numero di token WordPiece\")\n",
    "axes[1].legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"../results/plots/token_length_distribution.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f0685",
   "metadata": {},
   "source": [
    "## 1.5 — Top TF-IDF terms per classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c804eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "train_df = dfs[\"train\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "for ax, label, color in zip(axes, [\"prem\", \"conc\"], [\"#4C72B0\", \"#DD8452\"]):\n",
    "    texts = train_df[train_df[\"Component\"] == label][\"Text\"].tolist()\n",
    "    tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 1), min_df=2)\n",
    "    X = tfidf.fit_transform(texts)\n",
    "\n",
    "    # Media TF-IDF per termine\n",
    "    mean_tfidf = np.asarray(X.mean(axis=0)).flatten()\n",
    "    feature_names = tfidf.get_feature_names_out()\n",
    "    top_indices = mean_tfidf.argsort()[-20:][::-1]\n",
    "\n",
    "    top_terms = [feature_names[i] for i in top_indices]\n",
    "    top_scores = [mean_tfidf[i] for i in top_indices]\n",
    "\n",
    "    ax.barh(range(len(top_terms)), top_scores, color=color)\n",
    "    ax.set_yticks(range(len(top_terms)))\n",
    "    ax.set_yticklabels(top_terms)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel(\"Media TF-IDF\")\n",
    "    ax.set_title(f\"Top 20 termini — {label}\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"../results/plots/top_tfidf_terms.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4a4af6",
   "metadata": {},
   "source": [
    "## 1.6 — Word Cloud per classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6073099",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "for ax, label, cmap in zip(axes, [\"prem\", \"conc\"], [\"Blues\", \"Oranges\"]):\n",
    "    texts = \" \".join(train_df[train_df[\"Component\"] == label][\"Text\"].tolist())\n",
    "    wc = WordCloud(\n",
    "        width=800,\n",
    "        height=400,\n",
    "        max_words=100,\n",
    "        colormap=cmap,\n",
    "        background_color=\"white\",\n",
    "        collocations=False,\n",
    "    ).generate(texts)\n",
    "    ax.imshow(wc, interpolation=\"bilinear\")\n",
    "    ax.set_title(f\"Word Cloud — {label}\", fontsize=14)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"../results/plots/wordclouds.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a6c103",
   "metadata": {},
   "source": [
    "## 1.7 — Overlap lessicale tra classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320b388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabolario per classe (solo training)\n",
    "prem_words = set()\n",
    "conc_words = set()\n",
    "\n",
    "for _, row in train_df.iterrows():\n",
    "    words = set(row[\"Text\"].lower().split())\n",
    "    if row[\"Component\"] == \"prem\":\n",
    "        prem_words.update(words)\n",
    "    else:\n",
    "        conc_words.update(words)\n",
    "\n",
    "overlap = prem_words & conc_words\n",
    "only_prem = prem_words - conc_words\n",
    "only_conc = conc_words - prem_words\n",
    "\n",
    "print(f\"Vocabolario premise:    {len(prem_words):,} parole uniche\")\n",
    "print(f\"Vocabolario conclusion: {len(conc_words):,} parole uniche\")\n",
    "print(\n",
    "    f\"Overlap:                {len(overlap):,} parole ({len(overlap) / len(prem_words | conc_words) * 100:.1f}%)\"\n",
    ")\n",
    "print(f\"Solo in prem:           {len(only_prem):,}\")\n",
    "print(f\"Solo in conc:           {len(only_conc):,}\")\n",
    "print('\\n→ L\"alto overlap lessicale spiega perché un modello BoW (TF-IDF) ha limiti: le due classi')\n",
    "print(\n",
    "    \"  condividono la maggior parte del vocabolario. BERTino riesce a distinguere grazie al contesto.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e51b65e",
   "metadata": {},
   "source": [
    "## 1.8 — Riepilogo EDA\n",
    "\n",
    "**Osservazioni chiave:**\n",
    "\n",
    "1. **Sbilanciamento:** ~80% premise, ~20% conclusioni → Macro-F1 è la metrica corretta per non ignorare la classe minoritaria\n",
    "2. **Lunghezza testi:** le premesse tendono ad essere più lunghe delle conclusioni (sia in parole che in token)\n",
    "3. **Troncamento WordPiece:** solo una piccola percentuale dei testi supera `max_length=256` → la scelta è appropriata\n",
    "4. **Overlap lessicale:** le due classi condividono gran parte del vocabolario → un modello BoW è penalizzato, un modello contestuale (BERTino) può sfruttare la struttura sintattica\n",
    "5. **Top TF-IDF terms:** i termini più discriminanti riflettono il linguaggio giuridico-argomentativo"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
